# ğŸ API Flask â€“ Stack Overflow Tag Predictor  
Par AgnÃ¨s Regaud â€“ Projet 5 â€“ OpenClassrooms â€“ Parcours IngÃ©nieur Machine Learning

![Tests](https://github.com/agnesR23/OC_IML_P5_Stackoverflow_tags_prediction_api_flask/actions/workflows/test.yml/badge.svg?branch=main)

Ce rÃ©pertoire contient le code source de lâ€™API Flask qui expose un service REST permettant de prÃ©dire automatiquement les tags dâ€™une question Stack Overflow Ã  partir de son titre et de son contenu.

ğŸ¯ Objectif

- Fournir une API REST simple et robuste pour recevoir une question (titre + corps) et retourner des prÃ©dictions de tags via deux modÃ¨lesâ€¯: supervisÃ© (CatBoost) et non supervisÃ© (NMF).

ğŸ“ Contenu du rÃ©pertoire

- app.py : point dâ€™entrÃ©e de lâ€™API Flask  
- artifacts/ : modÃ¨les entraÃ®nÃ©s et objets de prÃ©traitement (non versionnÃ©s, Ã  placer avant lancement)  
- environment.yml : environnement conda complet pour lâ€™API  
- environment-tests.yml : environnement lÃ©ger dÃ©diÃ© aux tests unitaires  
- tests/ : tests unitaires Pytest  
- Dockerfile : dÃ©finition de lâ€™image Docker pour lâ€™API  
- README.md : ce fichier

â–¶ï¸ Lancement local (conda)

conda env create -f environment.yml  
conda activate flask_app_env  
python app.py

# Lâ€™API sera accessible sur : http://localhost:5001

Important :  
- Avant de lancer lâ€™API en local, placez tous les artefacts nÃ©cessaires dans le dossier artifacts/.

ğŸ§ª Tests unitaires

conda env create -f environment-tests.yml  
conda activate stackoverflow_tests  
pytest

ğŸ³ Docker

docker build -t app_flask .  
docker run -p 5001:5001 app_flask

â–¶ï¸ DÃ©ploiement sur AWS ECS Fargate

- Construisez et poussez lâ€™image Docker sur Amazon ECR.  
- DÃ©ployez la task ECS avec le port 5001 ouvert en inbound.  
- Placez les artefacts (modÃ¨les, preprocess) dans le container via un volume ou lors du build.  
- AprÃ¨s chaque dÃ©ploiement, rÃ©cupÃ©rez lâ€™IP publique de la tÃ¢che ECS pour mettre Ã  jour le dashboard Streamlit (voir README du dashboard pour la procÃ©dure).

ğŸ” Tests automatisÃ©s

Le projet comprend une suite de tests unitaires automatisÃ©s avec pytest, couvrant notamment :

- PrÃ©traitement des donnÃ©es (normalisation, nettoyage)  
- Endpoints de lâ€™API (/predict, etc.) en mode CatBoost et NMF  
- Gestion des erreurs et des cas limites (artefacts manquants, mauvais champs, etc.)  
- Mocks pour les dÃ©pendances externes

âš™ï¸ IntÃ©gration continue

Les tests sont exÃ©cutÃ©s automatiquement via GitHub Actions Ã  chaque push grÃ¢ce Ã  un workflow CI (`test.yml`).

---

Note :  
- Les artefacts sont nÃ©cessaires au fonctionnement de lâ€™API mais **non versionnÃ©s** (non inclus dans le repo).  
- Lâ€™API doit Ãªtre exposÃ©e publiquement (port 5001) pour Ãªtre consommÃ©e par le dashboard Streamlit Cloud.
